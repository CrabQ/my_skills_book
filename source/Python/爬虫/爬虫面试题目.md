# 爬虫面试题目

什么是线程同步和异步
线程同步：多个线程同时访问同一资源，等待资源访问结束，浪费时间，效率低
线程异步：在访问资源时在空闲等待时同时访问其他资源，实现多线程机制

网络同步和异步
同步：提交请求->等待服务器处理->处理完毕返回 这个期间客户端浏览器不能干任何事
异步: 请求通过事件触发->服务器处理（这是浏览器仍然可以作其他事情）->处理完毕
链表和顺序表储存时各自有什么优点？
1. 顺序表存储
原理：顺序表存储是将数据元素放到一块连续的内存存储空间，存取效率高，速度快。但是不可以动态增加长度
优点：存取速度高效，通过下标来直接存储
缺点：1. 插入和删除比较慢，2. 不可以增长长度
比如：插入或者删除一个元素时，整个表需要遍历移动元素来重新排一次顺序
2. 链表存储
原理：链表存储是在程序运行过程中动态的分配空间，只要存储器还有空间，就不会发生存储溢出问题
优点：插入和删除速度快，保留原有的物理顺序，比如：插入或者删除一个元素时，只需要改变指针指向即可
缺点：查找速度慢，因为查找时，需要循环链表访问

使用redis搭建分布式系统时如何处理网络延迟和网络异常？　　
由于网络异常的存在，分布式系统中请求结果存在“三态”的概念，即三种状态：“成功”、“失败”、“超时（未知）”
当出现“超时”时可以通过发起读取数据的操作以验证 RPC 是否成功（例如银行系统的做法）
另一种简单的做法是，设计分布式协议时将执行步骤设计为可重试的，即具有所谓的“幂等性”

数据仓库是什么？
数据仓库是一个面向主题的、集成的、稳定的、反映历史变化的、随着时间的流逝发生变化的数据集合。它主要支持管理人员的决策分析。
数据仓库收集了企业相关内部和外部各个业务系统数据源、归档文件等一系列历史数据，最后转化成企业需要的战略决策信息。
1. 特点：
面向主题：根据业务的不同而进行的内容划分；
集成特性：因为不同的业务源数据具有不同的数据特点，当业务源数据进入到数据仓库时，需要采用统一的编码格式进行数据加载，从而保证数据仓库中数据的唯一性；
非易失性：数据仓库通过保存数据不同历史的各种状态，并不对数据进行任何更新操作。
历史特性：数据保留时间戳字段，记录每个数据在不同时间内的各种状态。
你是否了解MySQL数据库的几种引擎？
1. InnoDB是一个健壮的事务型存储引擎
更新密集的表。InnoDB存储引擎特别适合处理多重并发的更新请求。
事务。InnoDB存储引擎是支持事务的标准MySQL存储引擎。
自动灾难恢复。与其它存储引擎不同，InnoDB表能够自动从灾难中恢复。
外键约束。MySQL支持外键的存储引擎只有InnoDB。
支持自动增加列AUTO_INCREMENT属性。
一般来说，如果需要事务支持，并且有较高的并发读取频率，InnoDB是不错的选择。
2. 使用MySQL Memory存储引擎的出发点是速度。为得到最快的响应时间，采用的逻辑存储介质是系统内存。
虽然在内存中存储表数据确实会提供很高的性能，但当mysqld守护进程崩溃时，所有的Memory数据都会丢失。
获得速度的同时也带来了一些缺陷。　 　
一般在以下几种情况下使用Memory存储引擎：
    1. 目标数据较小，而且被非常频繁地访问。在内存中存放数据，所以会造成内存的使用，可以通过参数max_heap_table_size控制Memory表的大小，设置此参数，就可以限制Memory表的最大大小。
    2. 如果数据是临时的，而且要求必须立即可用，那么就可以存放在内存表中。
    3. 存储在Memory表中的数据如果突然丢失，不会对应用服务产生实质的负面影   响。

简述一下爬虫程序执行的流程
获取想要的页面
根据规则进行解析
解析数据入库
爬虫在向数据库存数据开始和结束都会发一条消息，是scrapy 哪个模块实现的?
Item Pipeline
爬取下来的数据如何去重，说一下具体的算法依据。
通过 MD5 生成电子指纹来判断页面是否改变
nutch 去重。nutch 中 digest 是对采集的每一个网页内容的 32 位哈希值，如果两个网页内容完全一样，它们的 digest值肯定会一样。
说一下 numpy 和 pandas 的区别?分别的应用场景?
Numpy 是 数值计算 的扩展包，纯数学。
Pandas 做 数据处理以矩阵为基础的数学计算模块。提供了一套名为 DataFrame 的数据结构，比较契合统计分析中的表结构，并且提供了计算接口，可用 Numpy 或其它方式进行计算
写爬虫是用多进程好?还是多线程好? 为什么?
在这里我们进行分类讨论：
1、CPU密集型代码(各种循环处理、计数等等)，在这种情况下，由于计算工作多，ticks计数很快就会达到阈值，然后触发GIL的释放与再竞争（多个线程来回切换当然是需要消耗资源的），所以python下的多线程对CPU密集型代码并不友好。
2、IO密集型代码(文件处理、网络爬虫等)，多线程能够有效提升效率(单线程下有IO操作会进行IO等待，造成不必要的时间浪费，而开启多线程能在线程A等待时，自动切换到线程B，可以不浪费CPU的资源，从而能提升程序执行效率)。所以python的多线程对IO密集型代码比较友好。
而在python3.x中，GIL不使用ticks计数，改为使用计时器（执行时间达到阈值后，当前线程释放GIL），这样对CPU密集型程序更加友好，但依然没有解决GIL导致的同一时间只能执行一个线程的问题，所以效率依然不尽如人意。
多核性能
多核多线程比单核多线程更差，原因是单核下多线程，每次释放GIL，唤醒的那个线程都能获取到GIL锁，所以能够无缝执行，但多核下，CPU0释放GIL后，其他CPU上的线程都会进行竞争，但GIL可能会马上又被CPU0拿到，导致其他几个CPU上被唤醒后的线程会醒着等待到切换时间后又进入待调度状态，这样会造成线程颠簸(thrashing)，导致效率更低
多进程为什么不会这样？
每个进程有各自独立的GIL，互不干扰，这样就可以真正意义上的并行执行，所以在python中，多进程的执行效率优于多线程(仅仅针对多核CPU而言)。
所以在这里说结论：多核下，想做并行提升效率，比较通用的方法是使用多进程，能够有效提高执行效率。

验证码如何处理
Scrapy 自带处理验证码
获取到验证码图片的 url， 调用第三方付费接口破解验证码
微信公众号数据如何抓取?
　　sogou 微信搜索数据
股票数据的获取目前有如下两种方法可以获取:
http/JavaScript 接口取数据
web-service 接口
Sina 股票数据接口
以大秦铁路(股票代码：601006)为例，如果要获取它的最新行情，只需访问新浪的股票数据，只需访问新浪的股票数据接口：http://hq.sinajs.cn/list=sh具体股票代码编号
分布式有哪些方案，哪一种最好?
celery、beanstalk，gearman
个人认为 gearman 比较好。原因主要有以下几点：
技术类型简单，维护成本低。
简单至上。能满足当前的技术需求即可 (分布式任务处理、异步同步任务同时支持、任务队列的持久化、维
有成熟的使用案例。instagram 就是使用的 gearman来完成图片的处理的相关任务，有成功的经验，我们当然应该借鉴。

python中常用的数据结构有哪些？请简要介绍一下。
python中常见的数据结构有：列表(list)，字典(dict)，元组(tuple)，字符串(string)，集合(set)，数字（int或long或float。。。）等。
其中，列表，元祖和字符串可以统一归为序列类，即这三种数据结构中的元素是有序的。比如，他们都有索引（下标）操作，还有切片、相加和长度(len)，最大值(max)，最小值(min)操作。这是他们的共同点。
补充：python中常见的数据结构可以统称为容器（container）。序列（如列表和元组）、映射（如字典）以及集合（set）是三类主要的容器。
另外，关于这个问题，面试官很容易引出另一个问题：python中的哪些数据类型是可变的，哪些是不可变的？
首先，可变/不可变是针对该对象所指向的内存中的值是否可变来判断的。如可变类型的数据类型有列表和字典，还有集合。不可变类型的数据类型有字符串，元组，数字。
就举个最简单的数字的例子，python中有小整数池的概念，即[-5,256]范围内的整数，python解释器对他们做了特殊处理，都放在内存中的固定位置，不会因为你的操作而发生变化。
现在：a = 1 ，然后我们又重新对a赋值，a = 2，在重新赋值的过程中，整数1所对应的内存地址没有和数字的大小都没有发生变化，还在内存中的固定位置。整数2也是如此。变化的是a的指针（这里引用C中的概念）从指向数字1变成数字2。a对象指向的内存中的值没有发生变化，因此数字是不可变类型的数据类型。字符串，元组也是同理。
简要描述python中单引号、双引号、三引号的区别。
首先，单引号和双引号在使用时基本上没有什么区别，唯一需要注意的是：当字符串中有单引号时，最好在外面使用双引号；当有双引号时，最好在外面使用单引号。

三引号一般不常用，除了用来做注释之外，还可以用来打印多行字符串。特殊用途，是可以打印多行字符串。
如何在一个function里设置一个全局的变量。
先说概念，全局变量是指定义在函数外部的变量。全局变量的作用域为全局。
局部变量是指定义在函数内部的变量。局部变量的作用域为函数内，除了函数就无效了。
这里举个例子，如果把函数比作国家，那么全局就是全球，全局变量好比是阿拉伯数字，每个国家都认识。
所以，根据定义可以知道，在函数内部是无法定义一个全局变量的，只能做到修改已经定义的全局变量。
python里面如何拷贝一个对象？（赋值、浅拷贝、深拷贝的区别）
在python中如何拷贝一个对象是需要根据具体的需求来定的。

（1）赋值：其实就是对象的引用。相当于C的指针，修改了其中一个对象，另一个跟着改变。注意对于不可变对象而言，如果修改了其中一个对象，就相当于修改它的指针指向，另一个对象是不会跟着变化的。
```
1 a = ['1', '2'] # a是一个可变对象
2 b = a
3 a = a.pop()
4 print(b) # 修改了a，b也跟着变

1 ['1']
```
当a为不可变对象时：
```
1 a = 1
2 b = a
3 a = 2
4 print('b = {}'.format(b))

1 b = 1
```

（2）浅拷贝：拷贝父对象，但是不会拷贝父对象的子对象。（具体的方法有：b = copy.copy(a)，切片如b = a[1:4]）
```
1 a = {1: [1, 2, 3]}
2 b = a.copy()
3 print(a, b)
4 a[1].append(4)
5 print(a, b)

{1: [1, 2, 3]} {1: [1, 2, 3]}
{1: [1, 2, 3, 4]} {1: [1, 2, 3, 4]}
```
当a为不可变对象时：
```
1 import copy
2 a = 'TEST_STRING'
3 b = copy.copy(a)
4 print(a, b)
5 a = a.lower()
6 print(a, b)

1 TEST_STRING TEST_STRING
2 test_string TEST_STRING
```
 （3）深拷贝：完全拷贝了父对象和子对象（具体的方法有：b = copy.deepcopy(a)）
```
1 import copy
2 a = {1: [1, 2, 3]}
3 b = copy.deepcopy(a)
4 print(a, b)
5 a[1].append(4)
6 print(a, b)

1 {1: [1, 2, 3]} {1: [1, 2, 3]}
2 {1: [1, 2, 3, 4]} {1: [1, 2, 3]}
```
当a为不可变对象时：
```
1 import copy
2 a = 'TEST_STRING'
3 b = copy.deepcopy(a)
4 print(a, b)
5 a = a.lower()
6 print(a, b)

1 TEST_STRING TEST_STRING
2 test_string TEST_STRING
```
如果custname字符串的编码格式为uft-8,如何将custname的内容转化为gb18030的字符串？
先将custname编码格式转换为unicode，在转换为gb18030。即custname.decode('utf-8').encode('gb18030')。
注意：unicode编码是一种二进制编码，是转换编码的中间桥梁。比如需要将utf-8转换为gbk，那么就需要先转换为unicode（decode），再转为gbk（encode）。
请写出一段python代码实现删除list中的重复元素。
两种方法：

（1）利用字典的fromkeys来自动过滤重复值

（2）利用集合set的特性，元素是非重复的

方法一：

```
1 a = [1, 2, 3, 4, 5, 2, 3]
2
3 def fun1(a):
4     a = list(set(a))
5     print(a)
6
7 fun1(a)
```
方法二：

```
1 a = [1, 2, 3, 4, 5, 2, 3]
2
3 def fun1(a):
4     b = {}
5     b = b.fromkeys(a)
6     c = list(b.keys())
7     print(c)
8
9 c = fun1(a)
```
这两个参数是什么意思？args和 kwargs。
