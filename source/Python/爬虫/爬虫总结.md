# 爬虫总结

## 一. 爬虫基础

### 1.1 http基本原理

### 1.2 request

1. request method(请求方式)
2. request url(请求链接)
3. request headers(请求头)
4. request body(请求体)
一般承载的内容是 POST 请求中的 Form Data，即表单数据，而对于 GET 请求 Request Body 则为空。

### 1.3 response

1. response status code
2. response headers
3. response body

## 二. 基本库的使用

### 2.1 urllib

```python
from urllib.parse import urlencode, parse_qs, quote, unquote

data = {
    'q':'知道',
    'name':'aa'
}
url = 'https://www.baidu.com?'

# urlencode() 方法将其序列化为 URL 标准 GET 请求参数
encode_data = urlencode(data)

print(url + encode_data)
# https://www.baidu.com?q=%E7%9F%A5%E9%81%93&name=aa

print(parse_qs(encode_data))
# {'q': ['知道'], 'name': ['aa']}

# 将内容转化为 URL 编码的格式
print(quote('知道'))
# %E7%9F%A5%E9%81%93
print(unquote(r'%E7%9F%A5%E9%81%93'))
```

### 2.2 requests

```python
from requests import Request, Session

url = 'http://httpbin.org/post'
data = {
    'name': 'germey'
}
headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'
}
s = Session()
req = Request('POST', url, data=data, headers=headers)
prepped = s.prepare_request(req)
r = s.send(prepped)
print(r.text)

```

- [request_基础](./example/request_基础.md)
- [request_requests请求回应的网页乱码](./example/request_requests请求回应的网页乱码.md)
- [request_session.headers.update(headers)无法对request.prepare()生效](./example/request_session.headers.update(headers)无法对request.prepare()生效.md)


### 2.3 正则表达式

- [re_基础](../re/re_基础.md)
- [re_实例](../re/re_实例.md)

## 三. 解析库的使用

### 3.1 xpath

```python
from lxml import etree
text = '''
<li class="li li-first" name="item"><a href="link.html">first item</a></li>
'''
html = etree.HTML(text)
result = html.xpath('//li[contains(@class, "li") and @name="item"]/a/text()')
print(result)
# ['first item']
```

- [lxml_xpath获取标签内的包括所有下级标签的所有文字内容](./example/lxml_xpath获取标签内的包括所有下级标签的所有文字内容.md)
- [lxml_使用lxml的etree.iterparse()解析大型XML](./example/lxml_使用lxml的etree.iterparse()解析大型XML.md)
- [lxml_etree.iterparse解析大型XML遇到命名空间的问题](./example/lxml_etree.iterparse解析大型XML遇到命名空间的问题.md)

### 3.2 pyquery

```python
from pyquery import PyQuery as pq
doc = pq(html)
a = doc('a')
for item in a.items():
    print(item.attr('href'))
```

## 四. 数据存储

### 4.1 txt文本存储

### 4.2 json文件存储

- [json_解析json文件](./example/json_解析json文件.md)

### 4.3 csv文件存储

- [csv_解析csv、tsv文件](./example/csv_解析csv、tsv文件.md)
- [csv_通过csv.writer写入数据每行都会增加一个空行](./example/csv_通过csv.writer写入数据每行都会增加一个空行.md)
- [csv_以逗号分隔字符串,但忽略双引号内的逗号](./example/csv_以逗号分隔字符串,但忽略双引号内的逗号.md)

### 4.4 MySQL存储

- [pymysql_example](./example/pymysql_example.md)
- [mysql_实例](../sql/mysql/mysql_实例.md)
- [mysql_安装及问题](../sql/mysql/mysql_安装及问题.md)

### 4.5 redis存储

- [redis_实例](../sql/redis/redis_实例.md)
- [redis_安装及问题](../sql/redis/redis_安装及问题.md)

### 4.6 mongodb存储

- [mongodb_实例](../sql/mongodb/mongodb_实例.md)
- [mongodb_安装及问题](../sql/mongodb/mongodb_安装及问题.md)